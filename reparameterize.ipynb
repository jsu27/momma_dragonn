{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,5\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "list_of_models = ['wide_spi1']\n",
    "\n",
    "def load_model(model_prefix):\n",
    "    model_json_string = open(model_prefix+'.json').read()\n",
    "    model = model_from_json(model_json_string)\n",
    "    model.load_weights(model_prefix+'.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/amr1/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "model = load_model(list_of_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_equivalent_weights(W1, W2, new_W):\n",
    "    l1, c1, f1 = W1.shape\n",
    "    l2, c2, f2 = W2.shape\n",
    "    new_l, new_c, new_f = new_W.shape\n",
    "    for k in xrange(0, new_l):\n",
    "        for c in xrange(0, new_c):\n",
    "            for f in xrange(0, new_f):\n",
    "                w = 0\n",
    "                lb = max(0, k-(l1-1))\n",
    "                ub = min(k+1, l2)\n",
    "                for j in xrange(lb, ub):\n",
    "                    for cc in xrange(0, f1):\n",
    "                        w = w + (W1[k-j][c][cc]*W2[j][cc][f])\n",
    "                new_W[k][c][f] = w\n",
    "    return new_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2]]\n",
      "\n",
      " [[3 4]]]\n",
      "[[[5]\n",
      "  [6]]]\n",
      "[[[17.]]\n",
      "\n",
      " [[39.]]]\n"
     ]
    }
   ],
   "source": [
    "# small test for compute_equivalent_weights\n",
    "\n",
    "W1 = np.array([1,2,3,4]).reshape((2,1,2))\n",
    "W2 = np.array([5,6]).reshape((1,2,1))\n",
    "new_W = np.zeros((2,1,1))\n",
    "new_W = compute_equivalent_weights(W1, W2, new_W)\n",
    "print(W1)\n",
    "print(W2)\n",
    "print(new_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "\n",
    "def reparameterize (model):\n",
    "\n",
    "    # figure out old conv layers\n",
    "    config1 = model.layers[0].get_config()\n",
    "    config2 = model.layers[1].get_config()\n",
    "    W1 = model.layers[0].get_weights()[0]\n",
    "    W2 = model.layers[1].get_weights()[0]\n",
    "\n",
    "    filters = config2['filters']\n",
    "    kernel_size = config1['kernel_size'][0] + config2['kernel_size'][0] - 1\n",
    "    padding = config2['padding']\n",
    "    activation = config2['activation']\n",
    "    strides = config2['strides']\n",
    "    input_shape = config1['batch_input_shape'][1:]\n",
    "    \n",
    "    # set up new conv layer\n",
    "    new_model = Sequential()\n",
    "    new_model.add(Conv1D(input_shape=input_shape,\n",
    "                         filters=filters,\n",
    "                         kernel_size=kernel_size,\n",
    "                         padding=padding,\n",
    "                         activation=activation,\n",
    "                         strides=strides))\n",
    "    \n",
    "    # get weights for new conv layer\n",
    "    new_l, new_c, new_f = new_model.layers[0].get_weights()[0].shape\n",
    "    new_W = np.zeros((new_l, new_c, new_f))\n",
    "    new_W = compute_equivalent_weights(W1, W2, new_W)\n",
    "    \n",
    "    # get bias for new conv layer\n",
    "    new_b = model.layers[1].get_weights()[1]\n",
    "    \n",
    "    # set weight and bias\n",
    "    new_model.layers[0].set_weights((new_W, new_b))\n",
    "    \n",
    "    # copy over rest of model\n",
    "    for layer in model.layers[2:]:\n",
    "        new_layer = layer.__class__.from_config(layer.get_config())\n",
    "        new_layer.build(layer.input_shape)\n",
    "        print(new_layer.weights)\n",
    "        print(layer.weights)\n",
    "        new_layer.set_weights(layer.get_weights())\n",
    "        new_model.add(new_layer)\n",
    "        \n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[<tf.Variable 'separable_fc_3_W_pos:0' shape=(10, 25) dtype=float32_ref>, <tf.Variable 'separable_fc_3_W_chan:0' shape=(10, 1) dtype=float32_ref>]\n",
      "[<tf.Variable 'separable_fc_3/separable_fc_3_W_pos:0' shape=(10, 25) dtype=float32_ref>, <tf.Variable 'separable_fc_3/separable_fc_3_W_chan:0' shape=(10, 1) dtype=float32_ref>]\n",
      "[<tf.Variable 'kernel:0' shape=(10, 1) dtype=float32_ref>, <tf.Variable 'bias:0' shape=(1,) dtype=float32_ref>]\n",
      "[<tf.Variable 'dense_3/kernel:0' shape=(10, 1) dtype=float32_ref>, <tf.Variable 'dense_3/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "new_model = reparameterize (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "m1_conv = Model(inputs=model.layers[0].input,\n",
    "               outputs=model.layers[2].output)\n",
    "\n",
    "\n",
    "m2_conv = Model(inputs=new_model.layers[0].input,\n",
    "                outputs=new_model.layers[1].output)\n",
    "\n",
    "differences = np.abs(m1_conv.predict(test_set[:50])-m2_conv.predict(test_set[:50])) > 0.00001\n",
    "nonzeros = np.nonzero(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'linear',\n",
       " 'activity_regularizer': None,\n",
       " 'batch_input_shape': (None, 1000, 4),\n",
       " 'bias_constraint': None,\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'bias_regularizer': None,\n",
       " 'dilation_rate': (1,),\n",
       " 'dtype': u'float32',\n",
       " 'filters': 32,\n",
       " 'kernel_constraint': None,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'distribution': u'uniform',\n",
       "   'mode': u'fan_avg',\n",
       "   'scale': 1.0,\n",
       "   'seed': None}},\n",
       " 'kernel_regularizer': None,\n",
       " 'kernel_size': (16,),\n",
       " 'name': u'conv1d_5',\n",
       " 'padding': u'same',\n",
       " 'strides': (1,),\n",
       " 'trainable': True,\n",
       " 'use_bias': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3, 0),\n",
       " (2, 993, 0),\n",
       " (2, 994, 0),\n",
       " (4, 995, 0),\n",
       " (4, 998, 0),\n",
       " (5, 1, 0),\n",
       " (5, 997, 0),\n",
       " (10, 994, 0),\n",
       " (11, 995, 0),\n",
       " (13, 994, 0),\n",
       " (14, 0, 0),\n",
       " (14, 5, 0),\n",
       " (15, 0, 0),\n",
       " (15, 5, 0),\n",
       " (15, 994, 0),\n",
       " (16, 993, 0),\n",
       " (19, 0, 0),\n",
       " (19, 994, 0),\n",
       " (23, 0, 0),\n",
       " (24, 5, 0),\n",
       " (24, 994, 0),\n",
       " (25, 998, 0),\n",
       " (27, 0, 0),\n",
       " (28, 994, 0),\n",
       " (29, 1, 0),\n",
       " (29, 997, 0),\n",
       " (30, 995, 0),\n",
       " (32, 995, 0),\n",
       " (35, 996, 0),\n",
       " (37, 0, 0),\n",
       " (37, 3, 0),\n",
       " (38, 0, 0),\n",
       " (39, 0, 0),\n",
       " (39, 993, 0),\n",
       " (40, 2, 0),\n",
       " (41, 0, 0),\n",
       " (41, 996, 0),\n",
       " (42, 5, 0),\n",
       " (42, 994, 0),\n",
       " (44, 994, 0),\n",
       " (46, 1, 0),\n",
       " (47, 996, 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(*nonzeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict(test_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_model.predict(test_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randin = np.random.random((10,1000,4))\n",
    "model.predict(randin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(model.layers[4].get_weights()[1]) - np.array(new_model.layers[3].get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[4].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input modes [u'sequence']\n",
      "Output modes [u'output']\n",
      "FAILED: case  1 0.39401627 0.39200103\n",
      "FAILED: case  2 0.15938604 0.15784913\n",
      "FAILED: case  5 0.18128243 0.16244912\n",
      "FAILED: case  10 0.16516298 0.15933818\n",
      "FAILED: case  11 0.28714067 0.28160957\n",
      "FAILED: case  14 0.75377023 0.7325093\n",
      "FAILED: case  15 0.82159644 0.8211974\n",
      "FAILED: case  16 0.2690119 0.2648076\n",
      "FAILED: case  19 0.9966799 0.9965077\n",
      "FAILED: case  23 0.76464844 0.75866586\n",
      "FAILED: case  24 0.2794227 0.2731783\n",
      "FAILED: case  25 0.4613918 0.4547862\n",
      "FAILED: case  27 0.99787724 0.9977863\n",
      "FAILED: case  28 0.19252354 0.1857999\n",
      "FAILED: case  29 0.25868192 0.25697985\n",
      "FAILED: case  30 0.13521314 0.12945192\n",
      "FAILED: case  32 0.31833413 0.30927566\n",
      "FAILED: case  35 0.355323 0.33726615\n",
      "FAILED: case  37 0.085916184 0.0820961\n",
      "FAILED: case  38 0.5797198 0.5779358\n",
      "FAILED: case  39 0.22677837 0.19126107\n",
      "FAILED: case  40 0.5823371 0.57168263\n",
      "FAILED: case  41 0.41910475 0.4080838\n",
      "FAILED: case  42 0.17202832 0.16665243\n",
      "FAILED: case  44 0.114011705 0.1126624\n",
      "FAILED: case  46 0.45639697 0.45203546\n"
     ]
    }
   ],
   "source": [
    "# small test for reparameterize\n",
    "\n",
    "from momma_dragonn.data_loaders.hdf5_data_loader import MultimodalAtOnceDataLoader\n",
    "data = MultimodalAtOnceDataLoader('test_data.hdf5')\n",
    "test_set = np.array(data.X['sequence'][50:100])\n",
    "test_labels = np.array(data.Y['output'][50:100])\n",
    "\n",
    "model_preds = model.predict(test_set)\n",
    "new_model_preds = new_model.predict(test_set)\n",
    "\n",
    "tol = 0.00001\n",
    "fail = False\n",
    "for i, e in np.ndenumerate(model_preds):\n",
    "    if abs(e - new_model_preds[i]) > tol:\n",
    "        fail = True\n",
    "        print(\"FAILED: case \", i[0], e, new_model_preds[i])\n",
    "if(fail == False):\n",
    "    print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
