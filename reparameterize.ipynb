{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,5\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "list_of_models = ['wide_spi1']\n",
    "\n",
    "def load_model(model_prefix):\n",
    "    model_json_string = open(model_prefix+'.json').read()\n",
    "    model = model_from_json(model_json_string)\n",
    "    model.load_weights(model_prefix+'.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/amr1/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "model = load_model(list_of_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "\n",
    "def reparameterize (model):\n",
    "\n",
    "    # figure out old conv layers\n",
    "    config1 = model.layers[0].get_config()\n",
    "    W1 = model.layers[0].get_weights()[0]\n",
    "    config2 = model.layers[1].get_config()\n",
    "    W2 = model.layers[1].get_weights()[0]\n",
    "\n",
    "    filters = config2['filters']\n",
    "    kernel_size = config1['kernel_size'][0] + config2['kernel_size'][0] - 1\n",
    "    padding = config2['padding']\n",
    "    activation = config2['activation']\n",
    "    strides = config2['strides']\n",
    "    input_shape = config1['batch_input_shape'][1:]\n",
    "    \n",
    "    # set up new conv layer\n",
    "    new_model = Sequential()\n",
    "    new_model.add(Conv1D(input_shape=input_shape,\n",
    "                         filters=filters,\n",
    "                         kernel_size=kernel_size,\n",
    "                         padding=padding,\n",
    "                         activation=activation,\n",
    "                         strides=strides))\n",
    "    \n",
    "    # get weights for new conv layer\n",
    "    l1, c1, f1 = W1.shape\n",
    "    l2, c2, f2 = W2.shape\n",
    "    new_l, new_c, new_f = new_model.layers[0].get_weights()[0].shape\n",
    "    \n",
    "    new_W = np.zeros((new_l, new_c, new_f))\n",
    "    for k in xrange(0, new_l):\n",
    "        for c in xrange(0, new_c):\n",
    "            for f in xrange(0, new_f):\n",
    "                w = 0\n",
    "                lb = max(0, k-(l1-1))\n",
    "                ub = min(k+1, l2)\n",
    "                for j in xrange(lb, ub):\n",
    "                    for cc in xrange(0, f1):\n",
    "                        w = w + (W1[k-j][c][cc]*W2[j][cc][f])\n",
    "                new_W[k][c][f] = w\n",
    "    \n",
    "    # get bias for new conv layer\n",
    "    new_b = model.layers[1].get_weights()[1]\n",
    "    \n",
    "    # set weight and bias\n",
    "    new_model.layers[0].set_weights((new_W, new_b))\n",
    "    \n",
    "    # copy over rest of model\n",
    "    for layer in model.layers[2:]:\n",
    "        new_model.add(layer)\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_model = reparameterize (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv1D at 0x7f4f0aabbad0>,\n",
       " <keras.layers.core.Activation at 0x7f4f0aace3d0>,\n",
       " <keras.layers.pooling.MaxPooling1D at 0x7f4f0aace910>,\n",
       " <keras.layers.core.SeparableFC at 0x7f4f0a5f8f50>,\n",
       " <keras.layers.core.Dense at 0x7f4f0a59db90>,\n",
       " <keras.layers.core.Activation at 0x7f4f0a5f88d0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input modes [u'sequence']\n",
      "Output modes [u'output']\n",
      "FAILED: case  3 0.35747755 0.3470106\n",
      "FAILED: case  5 0.2940397 0.29324406\n",
      "FAILED: case  8 0.21484488 0.21513245\n",
      "FAILED: case  12 0.31092596 0.30761045\n",
      "FAILED: case  14 0.5050754 0.50520927\n",
      "FAILED: case  20 0.25404063 0.25903574\n",
      "FAILED: case  23 0.31186968 0.30043527\n",
      "FAILED: case  26 0.17476869 0.17211443\n",
      "FAILED: case  27 0.09961008 0.099342875\n",
      "FAILED: case  29 0.26790643 0.26186612\n",
      "FAILED: case  30 0.64360595 0.62310344\n",
      "FAILED: case  31 0.22456479 0.21259725\n",
      "FAILED: case  33 0.14903317 0.14518899\n",
      "FAILED: case  38 0.15994032 0.15906829\n",
      "FAILED: case  40 0.2818003 0.2806327\n",
      "FAILED: case  43 0.8915809 0.88913226\n",
      "FAILED: case  45 0.6767659 0.6717169\n",
      "FAILED: case  48 0.10540187 0.10089134\n",
      "FAILED: case  49 0.09348091 0.08839944\n"
     ]
    }
   ],
   "source": [
    "# small test\n",
    "\n",
    "from momma_dragonn.data_loaders.hdf5_data_loader import MultimodalAtOnceDataLoader\n",
    "data = MultimodalAtOnceDataLoader('test_data.hdf5')\n",
    "test_set = np.array(data.X['sequence'][:50])\n",
    "test_labels = np.array(data.Y['output'][:50])\n",
    "\n",
    "model_preds = model.predict(test_set)\n",
    "new_model_preds = new_model.predict(test_set)\n",
    "\n",
    "tol = 0.00001\n",
    "fail = False\n",
    "for i, e in np.ndenumerate(model_preds):\n",
    "    if abs(e - new_model_preds[i]) > tol:\n",
    "        fail = True\n",
    "        print(\"FAILED: case \", i[0], e, new_model_preds[i])\n",
    "if(fail == False):\n",
    "    print(\"SUCCESS!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
