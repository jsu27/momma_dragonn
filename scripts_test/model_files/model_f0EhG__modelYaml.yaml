input_config:
- dtype: float
  input_shape: [1, 4, 200]
  name: sequence
input_order: [sequence]
loss: {output: binary_crossentropy}
name: Graph
node_config:
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: sequence
  inputs: &id001 []
  merge_mode: concat
  name: conv1
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: conv1
  inputs: *id001
  merge_mode: concat
  name: conv1_act
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: conv1_act
  inputs: *id001
  merge_mode: concat
  name: conv2
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: conv2
  inputs: *id001
  merge_mode: concat
  name: conv2_act
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: conv2
  inputs: *id001
  merge_mode: concat
  name: max_pool
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: max_pool
  inputs: *id001
  merge_mode: concat
  name: flatten
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: flatten
  inputs: *id001
  merge_mode: concat
  name: output
- concat_axis: -1
  create_output: false
  dot_axes: -1
  input: output
  inputs: *id001
  merge_mode: concat
  name: output_act
nodes:
  conv1:
    W_constraint: null
    W_learning_rate_multiplier: null
    W_regularizer: null
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_learning_rate_multiplier: null
    b_regularizer: null
    border_mode: valid
    cache_enabled: true
    custom_name: conv1
    dim_ordering: th
    init: glorot_uniform
    name: Convolution2D
    nb_col: 10
    nb_filter: 50
    nb_row: 4
    subsample: &id002 !!python/tuple [1, 1]
    trainable: true
  conv1_act: {activation: relu, cache_enabled: true, custom_name: conv1_act, name: Activation,
    trainable: true}
  conv2:
    W_constraint: null
    W_learning_rate_multiplier: null
    W_regularizer: null
    activation: linear
    activity_regularizer: null
    b_constraint: null
    b_learning_rate_multiplier: null
    b_regularizer: null
    border_mode: valid
    cache_enabled: true
    custom_name: conv2
    dim_ordering: th
    init: glorot_uniform
    name: Convolution2D
    nb_col: 10
    nb_filter: 50
    nb_row: 1
    subsample: *id002
    trainable: true
  conv2_act: {activation: relu, cache_enabled: true, custom_name: conv2_act, name: Activation,
    trainable: true}
  flatten: {cache_enabled: true, custom_name: flatten, name: Flatten, trainable: true}
  max_pool:
    border_mode: valid
    cache_enabled: true
    custom_name: max_pool
    dim_ordering: th
    name: MaxPooling2D
    pool_size: !!python/tuple [1, 40]
    strides: !!python/tuple [1, 40]
    trainable: true
  output: {W_constraint: null, W_learning_rate_multiplier: null, W_regularizer: null,
    activation: linear, activity_regularizer: null, b_constraint: null, b_learning_rate_multiplier: null,
    b_regularizer: null, cache_enabled: true, custom_name: output, init: glorot_uniform,
    input_dim: null, name: Dense, output_dim: 2, trainable: true}
  output_act: {activation: sigmoid, cache_enabled: true, custom_name: output_act,
    name: Activation, trainable: true}
optimizer: {beta_1: 0.8999999761581421, beta_2: 0.9990000128746033, epsilon: 1.0e-08,
  lr: 0.0010000000474974513, name: Adam}
output_config:
- concat_axis: -1
  dot_axes: -1
  input: output_act
  inputs: []
  merge_mode: concat
  name: output
output_order: [output]
