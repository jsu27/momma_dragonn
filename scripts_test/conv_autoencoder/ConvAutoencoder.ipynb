{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'momma_dragonn' from '/Users/avantishrikumar/Research/momma_dragonn/momma_dragonn/__init__.pyc'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import simdna\n",
    "import simdna.synthetic as synthetic\n",
    "from avutils import util\n",
    "import numpy as np\n",
    "import momma_dragonn\n",
    "reload(momma_dragonn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_sequences_set(seq_length, num_seqs, motif_names, mean_motifs=1, min_motifs=0, max_motifs=2, zero_prob=0):\n",
    "    loadedMotifs = synthetic.LoadedEncodeMotifs(simdna.ENCODE_MOTIFS_PATH, pseudocountProb=0.001)\n",
    "    embedInBackground = synthetic.EmbedInABackground(\n",
    "        backgroundGenerator=synthetic.ZeroOrderBackgroundGenerator(seqLength=seq_length)\n",
    "        , embedders=[\n",
    "            synthetic.RepeatedEmbedder(\n",
    "            synthetic.SubstringEmbedder(\n",
    "                #synthetic.ReverseComplementWrapper(\n",
    "                substringGenerator=synthetic.PwmSamplerFromLoadedMotifs(\n",
    "                    loadedMotifs=loadedMotifs,motifName=motifName)\n",
    "                #),\n",
    "                ,positionGenerator=synthetic.UniformPositionGenerator()),\n",
    "            quantityGenerator=synthetic.ZeroInflater(synthetic.MinMaxWrapper(\n",
    "                synthetic.PoissonQuantityGenerator(mean_motifs),\n",
    "                theMax=max_motifs, theMin=min_motifs), zeroProb=zero_prob)\n",
    "            )\n",
    "            for motifName in motif_names\n",
    "        ]\n",
    "    )\n",
    "    sequenceSetGenerator = synthetic.GenerateSequenceNTimes(embedInBackground, num_seqs)\n",
    "    return sequenceSetGenerator\n",
    "\n",
    "def one_hot_encode_sequences_set(sequence_set_generator):\n",
    "    one_hot_encoded_sequences = []\n",
    "    for sequence in sequence_set_generator.generateSequences():\n",
    "        one_hot_encoded_sequences.append(avutils.util.seq_to_2d_image(sequence.seq))\n",
    "    return np.array(one_hot_encoded_sequences)\n",
    "\n",
    "seq_length=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot_data_train = one_hot_encode_sequences_set(\n",
    "                generate_sequences_set(\n",
    "                    seq_length=seq_length, num_seqs=5000, motif_names=[\"CTCF_known1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot_data_valid = one_hot_encode_sequences_set(\n",
    "                        generate_sequences_set(\n",
    "                        seq_length=seq_length, num_seqs=1000, motif_names=[\"CTCF_known1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import momma_dragonn\n",
    "reload(momma_dragonn)\n",
    "reload(momma_dragonn.data_loaders)\n",
    "reload(momma_dragonn.data_loaders.core)\n",
    "\n",
    "def model_creator_func():\n",
    "    from keras.models import Graph\n",
    "    graph = Graph() \n",
    "    graph.add_input(name=\"sequence\", input_shape=(1,4,seq_length))\n",
    "    graph.add_node(\n",
    "        keras.layers.convolutional.Convolution2D(\n",
    "            nb_filter=, nb_row=, nb_col=, W_contraint=keras.constraints.MaxNorm(m=7, axis=1)),\n",
    "        name=\"conv1\", input=\"sequence\")\n",
    "    graph.add_output(name=\"output\", input=\"\")\n",
    "    graph.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss={\"output\": \"one_hot_from_logits_categorical_cross_entropy\"}\n",
    "    )\n",
    "    return graph\n",
    "    \n",
    "\n",
    "#data loaders\n",
    "train_data_loader = momma_dragonn.data_loaders.core.AtOnceDataLoader_XYDictAPI(\n",
    "                        X={'sequence': one_hot_data_train}, Y={'output': one_hot_data_train})\n",
    "valid_data_loader = momma_dragonn.data_loaders.core.AtOnceDataLoader_XYDictAPI(\n",
    "                        X={'sequence': one_hot_data_valid}, Y={'output': one_hot_data_valid})\n",
    "#model creator\n",
    "model_creator = momma_dragonn.model_creators.flexible_keras.KerasModelFromFunc(\n",
    "    func=model_creator_func,\n",
    "    model_wrapper_class=momma_dragonn.model_wrappers.keras_model_wrappers.KerasGraphModelWrapper)\n",
    "#model evaluator\n",
    "model_evaluator = momma_dragonn.model_evaluators.GraphAccuracyStats(\n",
    "    key_metric=\"onehot_rows_crossent\", all_metrics=[\"onehot_rows_crossent\"])\n",
    "#stopping criterion\n",
    "stopping_criterion_config = {\"class\": \"EarlyStopping\", \"kwargs\": {\"max_epochs\": 300, \"epochs_to_wait\": 10}}\n",
    "#callbacks\n",
    "end_of_epoch_callbacks = [momma_dragonn.end_of_epoch_callbacks.PrintPerfAfterEpoch(print_trend=True)]\n",
    "#trainer\n",
    "trainer = momma_dragonn.model_trainers.keras_model_trainer.KerasFitGeneratorModelTrainer(\n",
    "    samples_per_epoch=3000, stopping_criterion_config=stopping_criterion_config)\n",
    "\n",
    "trainer.train(model_wrapper=model_creator.get_model_wrapper(),\n",
    "              model_evaluator=model_evaluator,\n",
    "              valid_data_loader=valid_data_loader,\n",
    "              other_data_loaders={'train': train_data_loader},\n",
    "              end_of_epoch_callbacks=end_of_epoch_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
